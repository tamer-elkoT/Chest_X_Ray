{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b772b993",
      "metadata": {
        "id": "b772b993"
      },
      "source": [
        "\n",
        "# Lung X‑ray Classification with VGG16 + InceptionV3 Features and Random Forest\n",
        "This notebook builds a **feature-extraction pipeline** using two CNN backbones (VGG16 and InceptionV3) pretrained on ImageNet, then trains a **Random Forest** on the concatenated deep features to classify chest X‑rays.\n",
        "\n",
        "**Dataset assumption:** images are arranged in a folder with one subfolder per class, e.g.\n",
        "```\n",
        "dataset_root/\n",
        "  Normal/\n",
        "  Viral Pneumonia/\n",
        "  Bacterial Pneumonia/\n",
        "  COVID-19/\n",
        "  Tuberculosis/\n",
        "```\n",
        "> Update `DATA_DIR` below to your dataset path on Kaggle/Colab/Local.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43008584",
      "metadata": {
        "id": "43008584"
      },
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1ddbcd",
      "metadata": {
        "id": "cc1ddbcd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, random, math, json, itertools, pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, InceptionV3\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as inc_preprocess\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import joblib\n",
        "\n",
        "print(tf.__version__)\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Determinism (best-effort)\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9dfd4d3",
      "metadata": {
        "id": "e9dfd4d3"
      },
      "source": [
        "## 2) Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aed5748b",
      "metadata": {
        "id": "aed5748b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "# CHANGE THIS to your dataset root (folder that contains class subfolders)\n",
        "DATA_DIR = \"/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset 4 types\"  # update path if needed\n",
        "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "# Model/image params\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE_VGG = (224, 224)\n",
        "IMG_SIZE_INC = (299, 299)\n",
        "\n",
        "# Train/val/test split\n",
        "TEST_SIZE = 0.15\n",
        "VAL_SIZE  = 0.15  # of the remaining after test split (stratified)\n",
        "\n",
        "# RandomForest params (tune as needed)\n",
        "RF_PARAMS = dict(\n",
        "    n_estimators=600,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=SEED,\n",
        "    class_weight=None # we'll pass sample_weight from class weights instead\n",
        ")\n",
        "\n",
        "USE_PCA = False   # switch to True to enable PCA\n",
        "PCA_VARIANCE = 0.98  # keep 98% variance if PCA is used\n",
        "\n",
        "OUTPUT_DIR = \"./artifacts_rf_vgg16_incv3\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bcf88a",
      "metadata": {
        "id": "a4bcf88a"
      },
      "source": [
        "## 3) Load file paths & labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a812b2f0",
      "metadata": {
        "id": "a812b2f0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def list_images_and_labels(root_dir):\n",
        "    classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "    filepaths, labels = [], []\n",
        "    for idx, cls in enumerate(classes):\n",
        "        cls_dir = os.path.join(root_dir, cls)\n",
        "        for fname in os.listdir(cls_dir):\n",
        "            fp = os.path.join(cls_dir, fname)\n",
        "            if os.path.isfile(fp) and fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                filepaths.append(fp)\n",
        "                labels.append(cls)  # keep label as string\n",
        "    return filepaths, labels, classes\n",
        "\n",
        "filepaths, labels, classes = list_images_and_labels(DATA_DIR)\n",
        "print(f\"Found {len(filepaths)} images across {len(classes)} classes: {classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d939153",
      "metadata": {
        "id": "3d939153"
      },
      "source": [
        "## 4) Stratified Train/Val/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d332fd6",
      "metadata": {
        "id": "0d332fd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# First split off test\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    filepaths, labels, test_size=TEST_SIZE, random_state=SEED, stratify=labels)\n",
        "\n",
        "# Then split train/val from trainval\n",
        "val_ratio = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=val_ratio, random_state=SEED, stratify=y_trainval)\n",
        "\n",
        "def show_split_counts(y_tr, y_va, y_te):\n",
        "    import collections\n",
        "    for name, y in [('train', y_tr), ('val', y_va), ('test', y_te)]:\n",
        "        c = collections.Counter(y)\n",
        "        print(name, dict(c))\n",
        "show_split_counts(y_train, y_val, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a017b2",
      "metadata": {
        "id": "30a017b2"
      },
      "source": [
        "## 5) Create tf.data pipelines (no labels shuffling leakage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b5e4e43",
      "metadata": {
        "id": "3b5e4e43"
      },
      "outputs": [],
      "source": [
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "class_to_index = {c:i for i,c in enumerate(classes)}\n",
        "y_train_idx = np.array([class_to_index[y] for y in y_train])\n",
        "y_val_idx   = np.array([class_to_index[y] for y in y_val])\n",
        "y_test_idx  = np.array([class_to_index[y] for y in y_test])\n",
        "\n",
        "def decode_and_resize(path, img_size, preprocess_fn):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, img_size, method=tf.image.ResizeMethod.BILINEAR)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = preprocess_fn(img)\n",
        "    return img\n",
        "\n",
        "def make_ds(paths, labels_idx, img_size, preprocess_fn, batch_size=BATCH_SIZE, shuffle=False):\n",
        "    ds_paths = tf.data.Dataset.from_tensor_slices(paths)\n",
        "    ds_labels = tf.data.Dataset.from_tensor_slices(labels_idx)\n",
        "    ds = tf.data.Dataset.zip((ds_paths, ds_labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(lambda p, y: (decode_and_resize(p, img_size, preprocess_fn), y), num_parallel_calls=AUTO)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTO)\n",
        "    return ds\n",
        "\n",
        "train_ds_vgg = make_ds(X_train, y_train_idx, IMG_SIZE_VGG, vgg_preprocess, shuffle=True)\n",
        "val_ds_vgg   = make_ds(X_val,   y_val_idx,   IMG_SIZE_VGG, vgg_preprocess)\n",
        "test_ds_vgg  = make_ds(X_test,  y_test_idx,  IMG_SIZE_VGG, vgg_preprocess)\n",
        "\n",
        "train_ds_inc = make_ds(X_train, y_train_idx, IMG_SIZE_INC, inc_preprocess, shuffle=True)\n",
        "val_ds_inc   = make_ds(X_val,   y_val_idx,   IMG_SIZE_INC, inc_preprocess)\n",
        "test_ds_inc  = make_ds(X_test,  y_test_idx,  IMG_SIZE_INC, inc_preprocess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f4f336",
      "metadata": {
        "id": "d0f4f336"
      },
      "source": [
        "## 6) Load VGG16 and InceptionV3 (feature extractors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7faf0a53",
      "metadata": {
        "id": "7faf0a53"
      },
      "outputs": [],
      "source": [
        "\n",
        "# VGG16 (no top) + global pooling\n",
        "vgg = VGG16(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE_VGG + (3,))\n",
        "vgg_out = tf.keras.Sequential([vgg, tf.keras.layers.GlobalAveragePooling2D()], name=\"VGG16_GAP\")\n",
        "\n",
        "# InceptionV3 (no top) + global pooling\n",
        "inc = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE_INC + (3,))\n",
        "inc_out = tf.keras.Sequential([inc, tf.keras.layers.GlobalAveragePooling2D()], name=\"InceptionV3_GAP\")\n",
        "\n",
        "# Freeze (we only use them for inference/feature extraction)\n",
        "vgg.trainable = False\n",
        "inc.trainable = False\n",
        "\n",
        "# Inspect output feature dims\n",
        "tmp_v = next(iter(train_ds_vgg.take(1)))[0]\n",
        "tmp_i = next(iter(train_ds_inc.take(1)))[0]\n",
        "print(\"VGG16 feature dim:\", vgg_out(tmp_v).shape[-1])\n",
        "print(\"InceptionV3 feature dim:\", inc_out(tmp_i).shape[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705e9fa5",
      "metadata": {
        "id": "705e9fa5"
      },
      "source": [
        "## 7) Extract deep features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91be2cea",
      "metadata": {
        "id": "91be2cea"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(model, ds):\n",
        "    feats = []\n",
        "    ys    = []\n",
        "    for batch_x, batch_y in ds:\n",
        "        f = model(batch_x, training=False).numpy()\n",
        "        feats.append(f); ys.append(batch_y.numpy())\n",
        "    return np.vstack(feats), np.concatenate(ys)\n",
        "\n",
        "Xv_train, y_train_np = extract_features(vgg_out, train_ds_vgg)\n",
        "Xv_val,   y_val_np   = extract_features(vgg_out, val_ds_vgg)\n",
        "Xv_test,  y_test_np  = extract_features(vgg_out, test_ds_vgg)\n",
        "\n",
        "Xi_train, _ = extract_features(inc_out, train_ds_inc)\n",
        "Xi_val,   _ = extract_features(inc_out, val_ds_inc)\n",
        "Xi_test,  _ = extract_features(inc_out, test_ds_inc)\n",
        "\n",
        "# Concatenate features\n",
        "X_train_feats = np.hstack([Xv_train, Xi_train])\n",
        "X_val_feats   = np.hstack([Xv_val,   Xi_val])\n",
        "X_test_feats  = np.hstack([Xv_test,  Xi_test])\n",
        "\n",
        "print(\"Train features shape:\", X_train_feats.shape)\n",
        "print(\"Val   features shape:\", X_val_feats.shape)\n",
        "print(\"Test  features shape:\", X_test_feats.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f09cfdd",
      "metadata": {
        "id": "4f09cfdd"
      },
      "source": [
        "## 8) Train Random Forest on concatenated features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa6a180",
      "metadata": {
        "id": "cfa6a180"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute class weights for imbalanced data (used as sample_weight)\n",
        "unique_classes = np.unique(y_train_np)\n",
        "cls_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train_np)\n",
        "cls_w_dict = {cls: w for cls, w in zip(unique_classes, cls_weights)}\n",
        "sample_weight_train = np.array([cls_w_dict[y] for y in y_train_np])\n",
        "\n",
        "if USE_PCA:\n",
        "    # Standardize -> PCA -> RF\n",
        "    steps = [\n",
        "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "        (\"pca\", PCA(n_components=PCA_VARIANCE, svd_solver=\"full\", random_state=SEED)),\n",
        "        (\"rf\", RandomForestClassifier(**RF_PARAMS))\n",
        "    ]\n",
        "else:\n",
        "    # Optional standardization before RF (helps some datasets; RF doesn't always need it)\n",
        "    steps = [\n",
        "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "        (\"rf\", RandomForestClassifier(**RF_PARAMS))\n",
        "    ]\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "pipeline.fit(X_train_feats, y_train_np, rf__sample_weight=sample_weight_train)\n",
        "\n",
        "# Evaluate on val\n",
        "y_val_pred = pipeline.predict(X_val_feats)\n",
        "val_acc = accuracy_score(y_val_np, y_val_pred)\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
        "print(classification_report(y_val_np, y_val_pred, target_names=classes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a3b0c2",
      "metadata": {
        "id": "47a3b0c2"
      },
      "source": [
        "## 9) Final evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c31e5a",
      "metadata": {
        "id": "f4c31e5a"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_test_pred = pipeline.predict(X_test_feats)\n",
        "test_acc = accuracy_score(y_test_np, y_test_pred)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\\n\")\n",
        "print(classification_report(y_test_np, y_test_pred, target_names=classes))\n",
        "\n",
        "cm = confusion_matrix(y_test_np, y_test_pred)\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "im = ax.imshow(cm, interpolation='nearest')\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=classes, yticklabels=classes,\n",
        "       ylabel='True label', xlabel='Predicted label', title='Confusion Matrix')\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6589f0a",
      "metadata": {
        "id": "f6589f0a"
      },
      "source": [
        "## 10) Save artifacts (model + label mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686ac7d5",
      "metadata": {
        "id": "686ac7d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "pipeline_path = os.path.join(OUTPUT_DIR, \"rf_vgg16_incv3_pipeline.joblib\")\n",
        "labels_json   = os.path.join(OUTPUT_DIR, \"classes.json\")\n",
        "joblib.dump(pipeline, pipeline_path)\n",
        "with open(labels_json, \"w\") as f:\n",
        "    json.dump({\"classes\": classes}, f, ensure_ascii=False, indent=2)\n",
        "print(\"Saved:\", pipeline_path)\n",
        "print(\"Saved:\", labels_json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78f9389",
      "metadata": {
        "id": "a78f9389"
      },
      "source": [
        "## 11) Inference helper (single image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e134c403",
      "metadata": {
        "id": "e134c403"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_pipeline_and_predict(img_path):\n",
        "    # Load artifacts\n",
        "    pipe = joblib.load(os.path.join(OUTPUT_DIR, \"rf_vgg16_incv3_pipeline.joblib\"))\n",
        "    with open(os.path.join(OUTPUT_DIR, \"classes.json\"), \"r\") as f:\n",
        "        classes_local = json.load(f)[\"classes\"]\n",
        "\n",
        "    # Prepare both inputs\n",
        "    def _prep(img_path, size, pre_fn):\n",
        "        img = tf.io.read_file(img_path)\n",
        "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "        img = tf.image.resize(img, size, method=tf.image.ResizeMethod.BILINEAR)\n",
        "        img = tf.cast(img, tf.float32)\n",
        "        img = pre_fn(img)\n",
        "        return img[None, ...]\n",
        "\n",
        "    v = _prep(img_path, IMG_SIZE_VGG, vgg_preprocess)\n",
        "    i = _prep(img_path, IMG_SIZE_INC, inc_preprocess)\n",
        "\n",
        "    # Feature extract\n",
        "    fv = vgg_out(v, training=False).numpy()\n",
        "    fi = inc_out(i, training=False).numpy()\n",
        "    feats = np.hstack([fv, fi])\n",
        "\n",
        "    # Predict\n",
        "    pred_idx = pipe.predict(feats)[0]\n",
        "    proba = None\n",
        "    if hasattr(pipe.named_steps[\"rf\"], \"predict_proba\"):\n",
        "        proba = pipe.named_steps[\"rf\"].predict_proba(feats)[0]\n",
        "    return classes_local[pred_idx], proba\n",
        "\n",
        "# Example (uncomment and set your image path)\n",
        "# pred, proba = load_pipeline_and_predict(\"/kaggle/input/.../example.png\")\n",
        "# print(pred, proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bf6151",
      "metadata": {
        "id": "36bf6151"
      },
      "source": [
        "\n",
        "## 12) Tips to improve accuracy\n",
        "- **Tune RF hyperparameters**: `n_estimators` (e.g., 800–1200), `max_depth`, `min_samples_split`, `min_samples_leaf`.\n",
        "- **Enable PCA** if feature dimensionality is large and noisy. Try keeping 95–99% variance.\n",
        "- **Balanced sampling**: The notebook uses `sample_weight` via computed class weights.\n",
        "- **Data cleaning**: Ensure corrupted or mislabeled images are removed.\n",
        "- **Backbone variations**: Try EfficientNetB0/B3 or DenseNet201 as additional feature sources and concatenate.\n",
        "- **More data**: Use augmented variants or external datasets if allowed by your project rules.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
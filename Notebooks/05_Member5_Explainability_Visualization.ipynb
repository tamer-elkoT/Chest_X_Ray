{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc3cdf0",
   "metadata": {},
   "source": [
    "# Chest X-Ray Multi‑Class Project — Role Notebook\n",
    "\n",
    "**Dataset:** Kaggle “Lungs Disease Dataset (4 types)” by Omkar Manohar Dalvi  \n",
    "**Classes:** Normal, Bacterial Pneumonia, Viral Pneumonia, COVID‑19, Tuberculosis\n",
    "\n",
    "> Use this notebook in **Google Colab**. If you’re running locally, adapt the Drive mount steps accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de20791",
   "metadata": {},
   "source": [
    "## Role — Member 5: Explainability & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff53b9",
   "metadata": {},
   "source": [
    "**Responsibilities**  \n",
    "- Implement **Grad‑CAM** for saliency/attention visualization  \n",
    "- Generate heatmaps for correct and incorrect predictions per class  \n",
    "- Create augmentation & performance visual assets for the report/presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbb687",
   "metadata": {},
   "source": [
    "## Environment & Paths\n",
    "\n",
    "- The code below mounts Google Drive (for persistence) and prepares base paths.  \n",
    "- Set `DATASET_DIR` to where the extracted dataset resides (after Kaggle download)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efeec2",
   "metadata": {},
   "source": [
    "## Grad‑CAM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd00ac6",
   "metadata": {},
   "source": [
    "We compute Grad‑CAM on the last convolutional layer of the backbone and overlay on the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Colab & Paths ===\n",
    "import os, sys, glob, json, random, shutil, time\n",
    "from pathlib import Path\n",
    "\n",
    "# If in Colab, mount Drive (safe to run elsewhere; it will just fail silently)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    IN_COLAB = True\n",
    "except Exception as e:\n",
    "    print(\"Not running on Colab or Drive not available:\", e)\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Project root inside Drive (you can change this)\n",
    "PROJECT_ROOT = Path('/content/drive/MyDrive/Chest_XRay_Project')\n",
    "PROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where the dataset will live (after download & unzip). Adjust as needed.\n",
    "DATASET_DIR = PROJECT_ROOT / 'lungs_dataset'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'outputs'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
    "\n",
    "for p in [OUTPUTS_DIR, MODELS_DIR, REPORTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATASET_DIR :\", DATASET_DIR)\n",
    "print(\"OUTPUTS_DIR :\", OUTPUTS_DIR)\n",
    "print(\"MODELS_DIR  :\", MODELS_DIR)\n",
    "print(\"REPORTS_DIR :\", REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e32d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np, matplotlib.pyplot as plt, json\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Load classes & best model\n",
    "with open(PROJECT_ROOT / 'classes.json') as f:\n",
    "    CLASS_NAMES = json.load(f)\n",
    "\n",
    "best_model_path = MODELS_DIR / 'best_model.keras'\n",
    "model = tf.keras.models.load_model(best_model_path)\n",
    "model.summary()\n",
    "\n",
    "# Helper: find last conv layer name\n",
    "def find_last_conv(model):\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.SeparableConv2D, tf.keras.layers.DepthwiseConv2D)):\n",
    "            return layer.name\n",
    "    # Try scanning nested layers\n",
    "    for layer in reversed(model.layers):\n",
    "        try:\n",
    "            for sub in reversed(layer.layers):\n",
    "                if isinstance(sub, (tf.keras.layers.Conv2D, tf.keras.layers.SeparableConv2D, tf.keras.layers.DepthwiseConv2D)):\n",
    "                    return sub.name\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise ValueError(\"No Conv layer found\")\n",
    "\n",
    "last_conv_name = find_last_conv(model)\n",
    "print(\"Last conv layer:\", last_conv_name)\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "def load_img(path):\n",
    "    img = Image.open(path).convert('RGB').resize(IMG_SIZE)\n",
    "    arr = np.array(img)/255.0\n",
    "    return arr[np.newaxis,...], img\n",
    "\n",
    "def grad_cam(model, img_array, last_conv_layer_name, class_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if class_index is None:\n",
    "            class_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, class_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1).numpy()\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= (heatmap.max() + 1e-8)\n",
    "    return heatmap, int(class_index)\n",
    "\n",
    "def overlay_heatmap(img_pil, heatmap, alpha=0.35):\n",
    "    # Resize heatmap to image size and overlay\n",
    "    heatmap = Image.fromarray(np.uint8(255 * heatmap)).resize(img_pil.size)\n",
    "    heatmap = np.array(heatmap)/255.0\n",
    "    heatmap = np.stack([heatmap]*3, axis=-1)\n",
    "    img = np.array(img_pil)/255.0\n",
    "    over = (1 - alpha) * img + alpha * heatmap\n",
    "    over = np.clip(over, 0, 1)\n",
    "    return over\n",
    "\n",
    "# Demo on a few test images per class\n",
    "test_root = DATASET_DIR / 'test'\n",
    "examples = []\n",
    "for cls in CLASS_NAMES:\n",
    "    cls_dir = test_root / cls\n",
    "    files = list(cls_dir.glob('*.png')) + list(cls_dir.glob('*.jpg')) + list(cls_dir.glob('*.jpeg'))\n",
    "    if files:\n",
    "        examples.append(files[0])\n",
    "\n",
    "for p in examples:\n",
    "    arr, img_pil = load_img(p)\n",
    "    preds = model.predict(arr, verbose=0)[0]\n",
    "    pred_idx = int(np.argmax(preds))\n",
    "    heat, ci = grad_cam(model, arr, last_conv_name, class_index=pred_idx)\n",
    "    over = overlay_heatmap(img_pil, heat)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(over)\n",
    "    plt.title(f\"True: {p.parent.name} | Pred: {CLASS_NAMES[pred_idx]} | Conf: {preds[pred_idx]:.3f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Augmentation gallery (reuses Member 2 layers) ===\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.05),\n",
    "    tf.keras.layers.RandomZoom(0.05),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def show_aug_gallery(path):\n",
    "    arr, img_pil = load_img(path)\n",
    "    imgs = [img_pil]\n",
    "    for _ in range(5):\n",
    "        x = augment(np.array([np.array(img_pil)/255.0]), training=True).numpy()[0]\n",
    "        imgs.append(Image.fromarray((x*255).astype('uint8')))\n",
    "\n",
    "    for i, im in enumerate(imgs):\n",
    "        plt.figure()\n",
    "        plt.imshow(im)\n",
    "        plt.title(f\"Augmented sample {i}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "if examples:\n",
    "    show_aug_gallery(str(examples[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
